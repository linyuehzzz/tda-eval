{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### **Synthetic microdate from sf1 using database reconstruction**\r\n",
    "HHGQ (3) $*$ VOTINGAGE (2) $*$ HISPANIC (2) $*$ RACE (63) $*$ SEX (2) [from sf1 constraints]  \r\n",
    "---------------->         \r\n",
    "HHGQ (8) $*$ VOTINGAGE (2) $*$ HISPANIC (2) $*$ CENRACE (63)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepare query constraints from sf1 (*cons*) \r\n",
    "\r\n",
    "*   P5: HISPANIC OR LATINO ORIGIN BY RACE\r\n",
    "*   P8: RACE\r\n",
    "*   P9: HISPANIC OR LATINO, AND NOT HISPANIC OR LATINO BY RACE\r\n",
    "*   P12A-G: SEX BY AGE BY RACE\r\n",
    "*   P43: GROUP QUARTERS POPULATION BY SEX BY AGE BY GROUP QUARTERS TYPE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %cd \"/content/gdrive/My Drive/Colab Notebooks/census_privacy\"\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "## P1: TOTAL POPULATION\r\n",
    "filename_p1 = 'franklin/sf1/franklin_P1.csv'\r\n",
    "data_p1 = pd.read_csv(filename_p1)\r\n",
    "data_p1 = data_p1.drop(columns=[\"FILEID\", \"STUSAB\", \"SUMLEV\", \"LOGRECNO\", \"REGION\", \"DIVISION\", \"STATE\", \"COUNTY\",\r\n",
    "                                \"TRACT\", \"BLOCK\", \"GEOID10\"])\r\n",
    "\r\n",
    "## P5: HISPANIC OR LATINO ORIGIN BY RACE\r\n",
    "filename_p5 = 'franklin/sf1/franklin_P5.csv'\r\n",
    "data_p5 = pd.read_csv(filename_p5)\r\n",
    "data_p5 = data_p5.drop(columns=[\"FILEID\", \"STUSAB\", \"SUMLEV\", \"LOGRECNO\", \"REGION\", \"DIVISION\", \"STATE\", \"COUNTY\",\r\n",
    "                                \"TRACT\", \"BLOCK\", \"P0050001\", \"P0050002\", \"P0050010\"])\r\n",
    "\r\n",
    "## P8: RACE\r\n",
    "filename_p8 = 'franklin/sf1/franklin_P8.csv'\r\n",
    "data_p8 = pd.read_csv(filename_p8)\r\n",
    "data_p8 = data_p8.drop(columns=[\"FILEID\", \"STUSAB\", \"SUMLEV\", \"LOGRECNO\", \"REGION\", \"DIVISION\", \"STATE\", \"COUNTY\",\r\n",
    "                                \"TRACT\", \"BLOCK\", \"P0080001\", \"P0080002\", \"P0080009\", \"P0080010\", \"P0080026\", \r\n",
    "                                \"P0080047\", \"P0080063\", \"P0080070\"])\r\n",
    "\r\n",
    "## P9: HISPANIC OR LATINO, AND NOT HISPANIC OR LATINO BY RACE\r\n",
    "filename_p9 = 'franklin/sf1/franklin_P9.csv'\r\n",
    "data_p9 = pd.read_csv(filename_p9)\r\n",
    "data_p9 = data_p9.drop(columns=[\"FILEID\", \"STUSAB\", \"SUMLEV\", \"LOGRECNO\", \"REGION\", \"DIVISION\", \"STATE\", \"COUNTY\",\r\n",
    "                                \"TRACT\", \"BLOCK\", \"P0090001\", \"P0090002\", \"P0090003\", \"P0090004\", \"P0090011\", \r\n",
    "                                \"P0090012\", \"P0090028\", \"P0090049\", \"P0090065\", \"P0090072\"])\r\n",
    "\r\n",
    "## P12A: SEX BY AGE (WHITE ALONE)\r\n",
    "filename_p12A = 'franklin/sf1/franklin_P12A.csv'\r\n",
    "data_p12A = pd.read_csv(filename_p12A)\r\n",
    "data_p12A[\"P012A00A\"] = sum([data_p12A[\"P012A0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(3, 7)])\r\n",
    "data_p12A[\"P012A00B\"] = sum([data_p12A[\"P012A0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(7, 26)])\r\n",
    "data_p12A[\"P012A00C\"] = sum([data_p12A[\"P012A0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(27, 31)])\r\n",
    "data_p12A[\"P012A00D\"] = sum([data_p12A[\"P012A0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(31, 50)])\r\n",
    "data_p12A = data_p12A[[\"P012A00A\", \"P012A00B\", \"P012A00C\", \"P012A00D\"]]\r\n",
    "\r\n",
    "## P12B: SEX BY AGE (BLACK OR AFRICAN AMERICAN ALONE)\r\n",
    "filename_p12B = 'franklin/sf1/franklin_P12B.csv'\r\n",
    "data_p12B = pd.read_csv(filename_p12B)\r\n",
    "data_p12B[\"P012B00A\"] = sum([data_p12B[\"P012B0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(3, 7)])\r\n",
    "data_p12B[\"P012B00B\"] = sum([data_p12B[\"P012B0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(7, 26)])\r\n",
    "data_p12B[\"P012B00C\"] = sum([data_p12B[\"P012B0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(27, 31)])\r\n",
    "data_p12B[\"P012B00D\"] = sum([data_p12B[\"P012B0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(31, 50)])\r\n",
    "data_p12B = data_p12B[[\"P012B00A\", \"P012B00B\", \"P012B00C\", \"P012B00D\"]]\r\n",
    "\r\n",
    "## P12C: SEX BY AGE (AMERICAN INDIAN AND ALASKA NATIVE ALONE)\r\n",
    "filename_p12C = 'franklin/sf1/franklin_P12C.csv'\r\n",
    "data_p12C = pd.read_csv(filename_p12C)\r\n",
    "data_p12C[\"P012C00A\"] = sum([data_p12C[\"P012C0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(3, 7)])\r\n",
    "data_p12C[\"P012C00B\"] = sum([data_p12C[\"P012C0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(7, 26)])\r\n",
    "data_p12C[\"P012C00C\"] = sum([data_p12C[\"P012C0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(27, 31)])\r\n",
    "data_p12C[\"P012C00D\"] = sum([data_p12C[\"P012C0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(31, 50)])\r\n",
    "data_p12C = data_p12C[[\"P012C00A\", \"P012C00B\", \"P012C00C\", \"P012C00D\"]]\r\n",
    "\r\n",
    "## P12D: SEX BY AGE (ASIAN ALONE)\r\n",
    "filename_p12D = 'franklin/sf1/franklin_P12D.csv'\r\n",
    "data_p12D = pd.read_csv(filename_p12D)\r\n",
    "data_p12D[\"P012D00A\"] = sum([data_p12D[\"P012D0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(3, 7)])\r\n",
    "data_p12D[\"P012D00B\"] = sum([data_p12D[\"P012D0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(7, 26)])\r\n",
    "data_p12D[\"P012D00C\"] = sum([data_p12D[\"P012D0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(27, 31)])\r\n",
    "data_p12D[\"P012D00D\"] = sum([data_p12D[\"P012D0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(31, 50)])\r\n",
    "data_p12D = data_p12D[[\"P012D00A\", \"P012D00B\", \"P012D00C\", \"P012D00D\"]]\r\n",
    "\r\n",
    "## P12E: SEX BY AGE (NATIVE HAWAIIAN AND OTHER PACIFIC ISLANDER ALONE)\r\n",
    "filename_p12E = 'franklin/sf1/franklin_P12E.csv'\r\n",
    "data_p12E = pd.read_csv(filename_p12E)\r\n",
    "data_p12E[\"P012E00A\"] = sum([data_p12E[\"P012E0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(3, 7)])\r\n",
    "data_p12E[\"P012E00B\"] = sum([data_p12E[\"P012E0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(7, 26)])\r\n",
    "data_p12E[\"P012E00C\"] = sum([data_p12E[\"P012E0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(27, 31)])\r\n",
    "data_p12E[\"P012E00D\"] = sum([data_p12E[\"P012E0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(31, 50)])\r\n",
    "data_p12E = data_p12E[[\"P012E00A\", \"P012E00B\", \"P012E00C\", \"P012E00D\"]]\r\n",
    "\r\n",
    "## P12F: SEX BY AGE (SOME OTHER RACE ALONE)\r\n",
    "filename_p12F = 'franklin/sf1/franklin_P12F.csv'\r\n",
    "data_p12F = pd.read_csv(filename_p12F)\r\n",
    "data_p12F[\"P012F00A\"] = sum([data_p12F[\"P012F0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(3, 7)])\r\n",
    "data_p12F[\"P012F00B\"] = sum([data_p12F[\"P012F0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(7, 26)])\r\n",
    "data_p12F[\"P012F00C\"] = sum([data_p12F[\"P012F0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(27, 31)])\r\n",
    "data_p12F[\"P012F00D\"] = sum([data_p12F[\"P012F0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(31, 50)])\r\n",
    "data_p12F = data_p12F[[\"GEOID10\", \"P012F00A\", \"P012F00B\", \"P012F00C\", \"P012F00D\"]]\r\n",
    "\r\n",
    "## P12G: SEX BY AGE (TWO OR MORE RACES)\r\n",
    "filename_p12G = 'franklin/sf1/franklin_P12G.csv'\r\n",
    "data_p12G = pd.read_csv(filename_p12G)\r\n",
    "data_p12G[\"P012G00A\"] = sum([data_p12G[\"P012G0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(3, 7)])\r\n",
    "data_p12G[\"P012G00B\"] = sum([data_p12G[\"P012G0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(7, 26)])\r\n",
    "data_p12G[\"P012G00C\"] = sum([data_p12G[\"P012G0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(27, 31)])\r\n",
    "data_p12G[\"P012G00D\"] = sum([data_p12G[\"P012G0%s\" % '{number:0{width}d}'.format(width=2, number=i)] \r\n",
    "                             for i in range(31, 50)])\r\n",
    "data_p12G = data_p12G[[\"P012G00A\", \"P012G00B\", \"P012G00C\", \"P012G00D\"]]\r\n",
    "\r\n",
    "## P43: GROUP QUARTERS POPULATION BY SEX BY AGE BY GROUP QUARTERS TYPE\r\n",
    "filename_p43 = 'franklin/sf1/franklin_P43.csv'\r\n",
    "data_p43 = pd.read_csv(filename_p43)\r\n",
    "data_p43[\"P043G00A\"] = data_p43[[\"P0430004\"]]\r\n",
    "data_p43[\"P043G00B\"] = data_p43[[\"P0430009\"]]\r\n",
    "data_p43[\"P043G00C\"] = data_p43[\"P0430014\"] + data_p43[\"P0430024\"]       \r\n",
    "data_p43[\"P043G00D\"] = data_p43[\"P0430019\"] + data_p43[\"P0430029\"]\r\n",
    "data_p43[\"P043G00E\"] = data_p43[[\"P0430035\"]]\r\n",
    "data_p43[\"P043G00F\"] = data_p43[[\"P0430040\"]]\r\n",
    "data_p43[\"P043G00G\"] = data_p43[\"P0430045\"] + data_p43[\"P0430055\"]       \r\n",
    "data_p43[\"P043G00H\"] = data_p43[\"P0430050\"] + data_p43[\"P0430060\"] \r\n",
    "data_p43 = data_p43[[\"P043G00A\", \"P043G00B\", \"P043G00C\", \"P043G00D\", \"P043G00E\", \"P043G00F\", \"P043G00G\", \"P043G00H\"]]                   \r\n",
    "\r\n",
    "cons = pd.concat([data_p1, data_p5, data_p8, data_p9, data_p12A, data_p12B, data_p12C, data_p12D, data_p12E, data_p12F, data_p12G1, data_p43], \r\n",
    "                 axis=1, join='inner')\r\n",
    "\r\n",
    "# ## drop all blocks with zero-population\r\n",
    "# cons = cons[(cons.T != 0).any()]\r\n",
    "# shift column \"GEOID10\" to first position\r\n",
    "first_column = cons.pop(\"GEOID10\")\r\n",
    "# insert column using insert(position,column_name,first_column) function\r\n",
    "cons.insert(0, \"GEOID10\", first_column)\r\n",
    "\r\n",
    "cons.to_csv(\"franklin/microdata/franklin_cons.csv\", index=False)\r\n",
    "cons"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optimize detailed histogram"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# %cd \"/content/gdrive/My Drive/Colab Notebooks/census_privacy\"\r\n",
    "import pandas as pd\r\n",
    "from gurobipy import Model, GRB, QuadExpr, quicksum\r\n",
    "import torch\r\n",
    "\r\n",
    "# define all the input data for the model\r\n",
    "filename_cons = 'franklin/microdata/franklin_cons.csv'\r\n",
    "cons = pd.read_csv(filename_cons)\r\n",
    "M = len(cons)                   # number of blocks\r\n",
    "# M = 1\r\n",
    "n1, n2, n3, n4, n5 = 3, 2, 2, 63, 2\r\n",
    "N = n1 * n2 * n3 * n4 * n5         # number of attribute combinations: HHGQ (3) ∗ VOTINGAGE (2) ∗ HISPANIC (2) ∗ RACE (63) ∗ SEX (2)\r\n",
    "Q = 5                           # number of queries\r\n",
    "\r\n",
    "N = n1 * n2 * n3 * n4 * n5\r\n",
    "A = torch.tensor(range(N))\r\n",
    "A = A.reshape([n1, n2, n3, n4, n5])\r\n",
    "\r\n",
    "# initialize model\r\n",
    "m = Model('od')\r\n",
    "\r\n",
    "# add objective function\r\n",
    "obj = QuadExpr()\r\n",
    "\r\n",
    "# add variables and constraints\r\n",
    "h = {}      ## detailed histogram (decision vairable)\r\n",
    "for i in range(M):\r\n",
    "    for j in range(N):\r\n",
    "        h[i, j] = m.addVar(obj=0, vtype=GRB.INTEGER, lb=0, ub=cons.iloc[i][\"P0010001\"], name=\"h_%d_%d\"%(i,j))\r\n",
    "m.update()\r\n",
    "\r\n",
    "## P5: HISPANIC OR LATINO ORIGIN BY RACE\r\n",
    "q1 = cons.loc[:, cons.columns.str.startswith(\"P005\")].to_numpy()\r\n",
    "res1 = {}\r\n",
    "for i in range(M):\r\n",
    "    col_idx = 0\r\n",
    "    for x in range(n3):  # hispanic\r\n",
    "        hist_idx_two_or_more = []\r\n",
    "        for y in range(n4):  # race   \r\n",
    "            if y >= 0 and y <= 5:\r\n",
    "                hist_idx = torch.flatten(A[:, :, x, y, :]).tolist()\r\n",
    "                res1[i, col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, lb=0, name=\"res1_%d_%d\"%(i,col_idx))\r\n",
    "                obj += res1[i, col_idx] * res1[i, col_idx]\r\n",
    "                m.addConstr(res1[i, col_idx] == q1[i, col_idx] - quicksum(h[i, j] for j in hist_idx))\r\n",
    "                m.update()\r\n",
    "                col_idx += 1\r\n",
    "            else:\r\n",
    "                hist_idx = torch.flatten(A[:, :, x, y, :]).tolist()\r\n",
    "                hist_idx_two_or_more.extend(hist_idx)\r\n",
    "        res1[i, col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, lb=0, name=\"res1_%d_%d\"%(i,col_idx))\r\n",
    "        obj += res1[i, col_idx] * res1[i, col_idx]\r\n",
    "        m.addConstr(res1[i, col_idx] == q1[i, col_idx] - quicksum(h[i, j] for j in hist_idx_two_or_more))\r\n",
    "        m.update()\r\n",
    "        col_idx += 1\r\n",
    "\r\n",
    "## P8: RACE\r\n",
    "q2 = cons.loc[:, cons.columns.str.startswith(\"P008\")].to_numpy()\r\n",
    "res2 = {}     \r\n",
    "for i in range(M):\r\n",
    "    col_idx = 0\r\n",
    "    for x in range(n4):  # race\r\n",
    "        hist_idx = torch.flatten(A[:, :, :, x, :]).tolist()\r\n",
    "        res2[i, col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, lb=0, name=\"res2_%d_%d\"%(i,col_idx))\r\n",
    "        obj += res2[i, col_idx] * res2[i, col_idx]\r\n",
    "        m.addConstr(res2[i, col_idx] == q2[i, col_idx] - quicksum(h[i, j] for j in hist_idx))\r\n",
    "        m.update()\r\n",
    "        col_idx += 1\r\n",
    "\r\n",
    "## P9: HISPANIC OR LATINO, AND NOT HISPANIC OR LATINO BY RACE\r\n",
    "q3 = cons.loc[:, cons.columns.str.startswith(\"P00900\")].to_numpy()\r\n",
    "res3 = {}     \r\n",
    "for i in range(M):\r\n",
    "    col_idx = 0\r\n",
    "    for x in range(n4):  # race\r\n",
    "        hist_idx = torch.flatten(A[:, :, 0, x, :]).tolist()\r\n",
    "        res3[i, col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, lb=0, name=\"res3_%d_%d\"%(i,col_idx))\r\n",
    "        obj += res3[i, col_idx] * res3[i, col_idx]\r\n",
    "        m.addConstr(res3[i, col_idx] == q3[i, col_idx] - quicksum(h[i, j] for j in hist_idx))\r\n",
    "        m.update()\r\n",
    "        col_idx += 1\r\n",
    "\r\n",
    "## P12: SEX BY AGE BY RACE\r\n",
    "q4 = cons.loc[:, cons.columns.str.startswith(\"P012\")].to_numpy()\r\n",
    "res4 = {}     \r\n",
    "for i in range(M):\r\n",
    "    col_idx, hist_idx_two_or_more = 0, []\r\n",
    "    for x in range(n4):  # race\r\n",
    "        for y in range(n5):  # sex\r\n",
    "            for z in range(n2):  # voting age\r\n",
    "                if x >= 0 and x <= 5:\r\n",
    "                    hist_idx = torch.flatten(A[:, z, :, x, y]).tolist()\r\n",
    "                    res4[i, col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, lb=0, name=\"res4_%d_%d\"%(i,col_idx))\r\n",
    "                    obj += res4[i, col_idx] * res4[i, col_idx]\r\n",
    "                    m.addConstr(res4[i, col_idx] == q4[i, col_idx] - quicksum(h[i, j] for j in hist_idx))\r\n",
    "                    m.update()\r\n",
    "                    col_idx += 1\r\n",
    "                else:\r\n",
    "                    hist_idx = torch.flatten(A[:, z, :, x, y]).tolist()\r\n",
    "                    hist_idx_two_or_more.extend(hist_idx)\r\n",
    "    res4[i, col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, lb=0, name=\"res4_%d_%d\"%(i,col_idx))\r\n",
    "    obj += res4[i, col_idx] * res4[i, col_idx]\r\n",
    "    m.addConstr(res4[i, col_idx] == q4[i, col_idx] - quicksum(h[i, j] for j in hist_idx_two_or_more))\r\n",
    "    m.update()\r\n",
    "\r\n",
    "## P43: GROUP QUARTERS POPULATION BY SEX BY AGE BY GROUP QUARTERS TYPE\r\n",
    "q5 = cons.loc[:, cons.columns.str.startswith(\"P043\")].to_numpy()\r\n",
    "res5 = {}     \r\n",
    "for i in range(M):\r\n",
    "    col_idx = 0\r\n",
    "    for x in range(n5):  # sex\r\n",
    "        for y in range(n2):  # voting age\r\n",
    "            for z in range(1, n1):  # hhgq\r\n",
    "                hist_idx = torch.flatten(A[z, y, :, :, x]).tolist()\r\n",
    "                res5[i, col_idx] = m.addVar(obj=0, vtype=GRB.INTEGER, lb=0, name=\"res5_%d_%d\"%(i,col_idx))\r\n",
    "                obj += res5[i, col_idx] * res5[i, col_idx]\r\n",
    "                m.addConstr(res5[i, col_idx] == q5[i, col_idx] - quicksum(h[i, j] for j in hist_idx))\r\n",
    "                m.update()\r\n",
    "                col_idx += 1            \r\n",
    "\r\n",
    "m.setObjective(obj, GRB.MINIMIZE)\r\n",
    "print(m)\r\n",
    "\r\n",
    "m.optimize()\r\n",
    "m.write('franklin/microdata/franklin_hist.sol')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit"
  },
  "interpreter": {
   "hash": "c00fa7b34b3c5b66eff7e79ef51c2365cee2c33a027f789c679999857520ea52"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}